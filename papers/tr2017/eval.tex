\section{Evaluation}
\label{sec:evaluate}

This section evaluates the costs of the various layers of abstraction
in our platform used to create the simplified end-to-end experience. 
The C++ of our platform breaks into two essential layers:
\begin{itemize}
\item \emph{\CON-core}: the \CO device runtime, against which we write C++ programs;
\item \emph{\MCN-common-packages}: the C++ and Static TypeScript wrapping \CON-core 
to make it known to \MC, against which we write Static TypeScript programs;
\end{itemize}
We evaluate the cost of these layers using a set of micro-benchmarks, written
in both C++ and Static TypeScript, for three targets: nrF52, SAMD21, and Atmega (representing
the micro:bit, CPX, and Uno, respectively). The C++ benchmarks isolate the performance
of \CO and provide a baseline, while the Static TypeScript benchmarks show the overhead
added by \MC. 

%\subsection{Implementation}
% •	\CO (SAMD21 and AVR): base runtime (C++ only)
% •	pxt
% •	pxt-common-packages: C++ and Static TypeScript
% •	pxt-adafruit
% •	pxt-arduino-uno
% •	pxt-monaco, pxt-blockly

\subsection{FLASH and RAM footprint}

\begin{itemize}

 % FLASH and RAM footprint
\item FLASH footprint of the combined runtime codebase split by role (\CON-core, \MCN-common-packages)
% Analyse MAP file. (Assuming PXT core is in build, else Michal to provide size of PXT core libs)?
\item RAM footprint of the combined runtime codebase, also split by role; 
% (libc, codal-core, pxt-common-packages, makecode). Analyse MAP file for static footprint. 
%Enable HEAP\_DEBUG, and run C++ blinky and PXT blinky.
% cost of async/fibers/handlers
\item Scaling of RAM footprint with number of active fibers (parallel recursive calls in TS. 
%      Should be predictable, but validates we scale linearly and sets some hard figures 
%      for a real device). C++ test.
\end{itemize}

\subsection{Time for common \CO operations}

\begin{itemize}
\item Context switch time (both in real terms (uS) and CPU instructions). 
% C++ test, flipping a GPIO or two duting context switch and measuring on scope.
\item Event handling time (both in real terms (uS) and CPU instructions. 
%      Both IMMEDIATE and THREADED mode). C++ test. flipping a GPIO or two during context 
%      switch sections and measuring on scope.
\item Async Procedure Call (APC) handling time (both in real terms (uS) and CPU instructions). 
% C++ test. flipping a GPIO or two during context switch and measuring on scope.
\end{itemize}

\subsection{Compile time of Static TypeScript}

%mmoskal [10:10 AM] 
%`pxt checkdocs --snippets --re perf --stats`
% [10:11] 
% I compile empty sample first twice, to reduce JIT costs
% [10:12] 
% also, the first "compile prep" is slightly more costly, since it parses a hex file

\begin{itemize}
\item Time taken to compile and link simple program in browser (can we use some existing apps 
      here as case studies? E.g. Smiley emoji and fireflies?
% microbenchmarks
% in addition, Arduino "examples"
% instrument via node? or shell?
\item \UF File Size comparisons to HEX and bin. Time taken to complete a UF2 flash operation 
    (c.f. equivalent DAPLINK flash on micro:bit and avrdude flash on uno?)
\end{itemize}

\subsection{C++, Native vs Bytecode}
% - program benchmarks for C++, compiled MakeCode, interpreted MakeCode
%     - APP: A simple blinky
%     - Measures CPU time, RAM, Flash consumption
\begin{itemize}
\item Tight loop performance of C++, TS, and Blocks e.g. flipping a GPIO. PXT native compile.
\item Tight loop performance of C++, TS, and Blocks e.g. flipping a GPIO. PXT bytecode interpreted.
\end{itemize}

\subsection{Hardware resources}

% - efficient use of hardware resources, compared to Arduino, which uses spin loops and doesn't always use the hardware (bit bangs instead)

